{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.2)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym.envs.toy_text.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8w/_4wmbnrj0jj8_z5pbnm42wxr0000gn/T/ipykernel_9249/3589865756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoy_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcategorical_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym.envs.toy_text.utils'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from gym import error, spaces, utils\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from contextlib import closing\n",
    "from io import StringIO\n",
    "from os import path\n",
    "from typing import Optional\n",
    "import pygame\n",
    "from pygame.constants import SRCALPHA\n",
    "import numpy as np\n",
    "\n",
    "from gym import Env, spaces, utils\n",
    "from gym.envs.toy_text.utils import categorical_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "MAPS = {\n",
    "    \"4x4\": [\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"],\n",
    "    \"8x8\": [\n",
    "        \"SFFFFFFF\",\n",
    "        \"FFFFFFFF\",\n",
    "        \"FFFHFFFF\",\n",
    "        \"FFFFFHFF\",\n",
    "        \"FFFHFFFF\",\n",
    "        \"FHHFFFHF\",\n",
    "        \"FHFFHFHF\",\n",
    "        \"FFFHFFFG\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "def generate_random_map(size=8, p=0.8):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0, 0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r, c) in discovered:\n",
    "                discovered.add((r, c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == \"G\":\n",
    "                        return True\n",
    "                    if res[r_new][c_new] != \"H\":\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice([\"F\", \"H\"], (size, size), p=[p, 1 - p])\n",
    "        res[0][0] = \"S\"\n",
    "        res[-1][-1] = \"G\"\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "\n",
    "class FrozenLakeEnv(Env):\n",
    "    \"\"\"\n",
    "    Frozen lake involves crossing a frozen lake from Start(S) to Goal(G) without falling into any Holes(H) by walking over\n",
    "    the Frozen(F) lake. The agent may not always move in the intended direction due to the slippery nature of the frozen lake.\n",
    "    ### Action Space\n",
    "    The agent takes a 1-element vector for actions.\n",
    "    The action space is `(dir)`, where `dir` decides direction to move in which can be:\n",
    "    - 0: LEFT\n",
    "    - 1: DOWN\n",
    "    - 2: RIGHT\n",
    "    - 3: UP\n",
    "    ### Observation Space\n",
    "    The observation is a value representing the agent's current position as\n",
    "    current_row * nrows + current_col (where both the row and col start at 0).\n",
    "    For example, the goal position in the 4x4 map can be calculated as follows: 3 * 4 + 3 = 15.\n",
    "    The number of possible observations is dependent on the size of the map.\n",
    "    For example, the 4x4 map has 16 possible observations.\n",
    "    ### Rewards\n",
    "    Reward schedule:\n",
    "    - Reach goal(G): +1\n",
    "    - Reach hole(H): 0\n",
    "    - Reach frozen(F): 0\n",
    "    ### Arguments\n",
    "    ```\n",
    "    gym.make('FrozenLake-v1', desc=None,map_name=\"4x4\", is_slippery=True)\n",
    "    ```\n",
    "    `desc`: Used to specify custom map for frozen lake. For example,\n",
    "        desc=[\"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\"].\n",
    "    `map_name`: ID to use any of the preloaded maps.\n",
    "        \"4x4\":[\n",
    "            \"SFFF\",\n",
    "            \"FHFH\",\n",
    "            \"FFFH\",\n",
    "            \"HFFG\"\n",
    "            ]\n",
    "        \"8x8\": [\n",
    "            \"SFFFFFFF\",\n",
    "            \"FFFFFFFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FFFFFHFF\",\n",
    "            \"FFFHFFFF\",\n",
    "            \"FHHFFFHF\",\n",
    "            \"FHFFHFHF\",\n",
    "            \"FFFHFFFG\",\n",
    "        ]\n",
    "    `is_slippery`: True/False. If True will move in intended direction with\n",
    "    probability of 1/3 else will move in either perpendicular direction with\n",
    "    equal probability of 1/3 in both directions.\n",
    "        For example, if action is left and is_slippery is True, then:\n",
    "        - P(move left)=1/3\n",
    "        - P(move up)=1/3\n",
    "        - P(move down)=1/3\n",
    "    ### Version History\n",
    "    * v1: Bug fixes to rewards\n",
    "    * v0: Initial versions release (1.0.0)\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render.modes\": [\"human\", \"ansi\", \"rgb_array\"]}\n",
    "\n",
    "    def __init__(self, desc=None, map_name=\"4x4\", is_slippery=True):\n",
    "        if desc is None and map_name is None:\n",
    "            desc = generate_random_map()\n",
    "        elif desc is None:\n",
    "            desc = MAPS[map_name]\n",
    "        self.desc = desc = np.asarray(desc, dtype=\"c\")\n",
    "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
    "        self.reward_range = (0, 1)\n",
    "\n",
    "        nA = 4\n",
    "        nS = nrow * ncol\n",
    "\n",
    "        self.initial_state_distrib = np.array(desc == b\"S\").astype(\"float64\").ravel()\n",
    "        self.initial_state_distrib /= self.initial_state_distrib.sum()\n",
    "\n",
    "        self.P = {s: {a: [] for a in range(nA)} for s in range(nS)}\n",
    "\n",
    "        def to_s(row, col):\n",
    "            return row * ncol + col\n",
    "\n",
    "        def inc(row, col, a):\n",
    "            if a == LEFT:\n",
    "                col = max(col - 1, 0)\n",
    "            elif a == DOWN:\n",
    "                row = min(row + 1, nrow - 1)\n",
    "            elif a == RIGHT:\n",
    "                col = min(col + 1, ncol - 1)\n",
    "            elif a == UP:\n",
    "                row = max(row - 1, 0)\n",
    "            return (row, col)\n",
    "\n",
    "        def update_probability_matrix(row, col, action):\n",
    "            newrow, newcol = inc(row, col, action)\n",
    "            newstate = to_s(newrow, newcol)\n",
    "            newletter = desc[newrow, newcol]\n",
    "            done = bytes(newletter) in b\"GH\"\n",
    "            reward = float(newletter == b\"G\")\n",
    "            return newstate, reward, done\n",
    "\n",
    "        for row in range(nrow):\n",
    "            for col in range(ncol):\n",
    "                s = to_s(row, col)\n",
    "                for a in range(4):\n",
    "                    li = self.P[s][a]\n",
    "                    letter = desc[row, col]\n",
    "                    if letter in b\"GH\":\n",
    "                        li.append((1.0, s, 0, True))\n",
    "                    else:\n",
    "                        if is_slippery:\n",
    "                            for b in [(a - 1) % 4, a, (a + 1) % 4]:\n",
    "                                li.append(\n",
    "                                    (1.0 / 3.0, *update_probability_matrix(row, col, b))\n",
    "                                )\n",
    "                        else:\n",
    "                            li.append((1.0, *update_probability_matrix(row, col, a)))\n",
    "\n",
    "        self.observation_space = spaces.Discrete(nS)\n",
    "        self.action_space = spaces.Discrete(nA)\n",
    "\n",
    "        # pygame utils\n",
    "        self.window_size = (min(64 * ncol, 512), min(64 * nrow, 512))\n",
    "        self.window_surface = None\n",
    "        self.hole_img = None\n",
    "        self.cracked_hole_img = None\n",
    "        self.ice_img = None\n",
    "        self.elf_images = None\n",
    "        self.goal_img = None\n",
    "        self.start_img = None\n",
    "\n",
    "    def step(self, a):\n",
    "        transitions = self.P[self.s][a]\n",
    "        i = categorical_sample([t[0] for t in transitions], self.np_random)\n",
    "        p, s, r, d = transitions[i]\n",
    "        self.s = s\n",
    "        self.lastaction = a\n",
    "        return (int(s), r, d, {\"prob\": p})\n",
    "\n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        return_info: bool = False,\n",
    "        options: Optional[dict] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        self.s = categorical_sample(self.initial_state_distrib, self.np_random)\n",
    "        self.lastaction = None\n",
    "\n",
    "        if not return_info:\n",
    "            return int(self.s)\n",
    "        else:\n",
    "            return int(self.s), {\"prob\": 1}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        desc = self.desc.tolist()\n",
    "        if mode == \"ansi\":\n",
    "            return self._render_text(desc)\n",
    "        else:\n",
    "            return self._render_gui(desc, mode)\n",
    "\n",
    "    def _render_gui(self, desc, mode):\n",
    "        if self.window_surface is None:\n",
    "            pygame.init()\n",
    "            pygame.display.set_caption(\"Frozen Lake\")\n",
    "            if mode == \"human\":\n",
    "                self.window_surface = pygame.display.set_mode(self.window_size)\n",
    "            else:  # rgb_array\n",
    "                self.window_surface = pygame.Surface(self.window_size)\n",
    "        if self.hole_img is None:\n",
    "            file_name = path.join(path.dirname(__file__), \"img/hole.png\")\n",
    "            self.hole_img = pygame.image.load(file_name)\n",
    "        if self.cracked_hole_img is None:\n",
    "            file_name = path.join(path.dirname(__file__), \"img/cracked_hole.png\")\n",
    "            self.cracked_hole_img = pygame.image.load(file_name)\n",
    "        if self.ice_img is None:\n",
    "            file_name = path.join(path.dirname(__file__), \"img/ice.png\")\n",
    "            self.ice_img = pygame.image.load(file_name)\n",
    "        if self.goal_img is None:\n",
    "            file_name = path.join(path.dirname(__file__), \"img/goal.png\")\n",
    "            self.goal_img = pygame.image.load(file_name)\n",
    "        if self.start_img is None:\n",
    "            file_name = path.join(path.dirname(__file__), \"img/stool.png\")\n",
    "            self.start_img = pygame.image.load(file_name)\n",
    "        if self.elf_images is None:\n",
    "            elfs = [\n",
    "                path.join(path.dirname(__file__), \"img/elf_left.png\"),\n",
    "                path.join(path.dirname(__file__), \"img/elf_down.png\"),\n",
    "                path.join(path.dirname(__file__), \"img/elf_right.png\"),\n",
    "                path.join(path.dirname(__file__), \"img/elf_up.png\"),\n",
    "            ]\n",
    "            self.elf_images = [pygame.image.load(f_name) for f_name in elfs]\n",
    "\n",
    "        board = pygame.Surface(self.window_size, flags=SRCALPHA)\n",
    "        cell_width = self.window_size[0] // self.ncol\n",
    "        cell_height = self.window_size[1] // self.nrow\n",
    "        smaller_cell_scale = 0.6\n",
    "        small_cell_w = smaller_cell_scale * cell_width\n",
    "        small_cell_h = smaller_cell_scale * cell_height\n",
    "\n",
    "        # prepare images\n",
    "        last_action = self.lastaction if self.lastaction is not None else 1\n",
    "        elf_img = self.elf_images[last_action]\n",
    "        elf_scale = min(\n",
    "            small_cell_w / elf_img.get_width(),\n",
    "            small_cell_h / elf_img.get_height(),\n",
    "        )\n",
    "        elf_dims = (\n",
    "            elf_img.get_width() * elf_scale,\n",
    "            elf_img.get_height() * elf_scale,\n",
    "        )\n",
    "        elf_img = pygame.transform.scale(elf_img, elf_dims)\n",
    "        hole_img = pygame.transform.scale(self.hole_img, (cell_width, cell_height))\n",
    "        cracked_hole_img = pygame.transform.scale(\n",
    "            self.cracked_hole_img, (cell_width, cell_height)\n",
    "        )\n",
    "        ice_img = pygame.transform.scale(self.ice_img, (cell_width, cell_height))\n",
    "        goal_img = pygame.transform.scale(self.goal_img, (cell_width, cell_height))\n",
    "        start_img = pygame.transform.scale(self.start_img, (small_cell_w, small_cell_h))\n",
    "\n",
    "        for y in range(self.nrow):\n",
    "            for x in range(self.ncol):\n",
    "                rect = (x * cell_width, y * cell_height, cell_width, cell_height)\n",
    "                if desc[y][x] == b\"H\":\n",
    "                    self.window_surface.blit(hole_img, (rect[0], rect[1]))\n",
    "                elif desc[y][x] == b\"G\":\n",
    "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
    "                    goal_rect = self._center_small_rect(rect, goal_img.get_size())\n",
    "                    self.window_surface.blit(goal_img, goal_rect)\n",
    "                elif desc[y][x] == b\"S\":\n",
    "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
    "                    stool_rect = self._center_small_rect(rect, start_img.get_size())\n",
    "                    self.window_surface.blit(start_img, stool_rect)\n",
    "                else:\n",
    "                    self.window_surface.blit(ice_img, (rect[0], rect[1]))\n",
    "\n",
    "                pygame.draw.rect(board, (180, 200, 230), rect, 1)\n",
    "\n",
    "        # paint the elf\n",
    "        bot_row, bot_col = self.s // self.ncol, self.s % self.ncol\n",
    "        cell_rect = (\n",
    "            bot_col * cell_width,\n",
    "            bot_row * cell_height,\n",
    "            cell_width,\n",
    "            cell_height,\n",
    "        )\n",
    "        if desc[bot_row][bot_col] == b\"H\":\n",
    "            self.window_surface.blit(cracked_hole_img, (cell_rect[0], cell_rect[1]))\n",
    "        else:\n",
    "            elf_rect = self._center_small_rect(cell_rect, elf_img.get_size())\n",
    "            self.window_surface.blit(elf_img, elf_rect)\n",
    "\n",
    "        self.window_surface.blit(board, board.get_rect())\n",
    "        if mode == \"human\":\n",
    "            pygame.display.update()\n",
    "        else:  # rgb_array\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(self.window_surface)), axes=(1, 0, 2)\n",
    "            )\n",
    "\n",
    "    @staticmethod\n",
    "    def _center_small_rect(big_rect, small_dims):\n",
    "        offset_w = (big_rect[2] - small_dims[0]) / 2\n",
    "        offset_h = (big_rect[3] - small_dims[1]) / 2\n",
    "        return (\n",
    "            big_rect[0] + offset_w,\n",
    "            big_rect[1] + offset_h,\n",
    "        )\n",
    "\n",
    "    def _render_text(self, desc):\n",
    "        outfile = StringIO()\n",
    "\n",
    "        row, col = self.s // self.ncol, self.s % self.ncol\n",
    "        desc = [[c.decode(\"utf-8\") for c in line] for line in desc]\n",
    "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
    "        if self.lastaction is not None:\n",
    "            outfile.write(f\"  ({['Left', 'Down', 'Right', 'Up'][self.lastaction]})\\n\")\n",
    "        else:\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\".join(\"\".join(line) for line in desc) + \"\\n\")\n",
    "\n",
    "        with closing(outfile):\n",
    "            return outfile.getvalue()\n",
    "\n",
    "\n",
    "# Elf and stool from https://franuka.itch.io/rpg-snow-tileset\n",
    "# All other assets by Mel Sawyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp_sarsa_agent(object):\n",
    "    def __init__(self, obs_n = 16, act_n = 4, learning_rate=0.3, gamma=0.98, e_greed=0.1):\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = e_greed\n",
    "        self.act_n = act_n\n",
    "        self.Q = np.zeros((obs_n, act_n))\n",
    "        self.pi = np.zeros((obs_n, act_n))\n",
    "        self.lr_min = 1e-5\n",
    "\n",
    "    def predict(self, S):\n",
    "        Q_values = self.Q[S]\n",
    "        maxQ = np.max(self.Q[S])\n",
    "\n",
    "        action = np.random.choice(np.where(Q_values == maxQ)[0])\n",
    "        return action\n",
    "\n",
    "    def policy(self, S):\n",
    "        if np.random.uniform(0, 1) >= (1.0 - self.epsilon):\n",
    "            action = self.predict(S)\n",
    "        else:\n",
    "            action = np.random.choice(self.act_n)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self, S, action, reward, S_prime, action_prime, done):\n",
    "        self.Q[S, action] += self.lr * \\\n",
    "        (reward + self.gamma * np.sum(self.pi[S_prime, :] * self.Q[S, :]) - self.Q[S, action])\n",
    "\n",
    "    def decay(self, epsilon_decay_rate, lr_decay_rate):\n",
    "        self.epsilon *= (1 - epsilon_decay_rate)\n",
    "        self.lr = max(self.lr_min, self.lr * (1 - lr_decay_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode_es(env, agent):\n",
    "    S = env.reset()\n",
    "    action = agent.policy(S)\n",
    "    \n",
    "    total_reward = 0\n",
    "    while (True):\n",
    "        S_prime, reward, done, _ = env.step(action)\n",
    "        action_prime = agent.policy(S_prime)\n",
    "        (S, action, reward, S_prime, action_prime, done)\n",
    "        agent.learn(S, action, reward, S_prime, action_prime, done)\n",
    "\n",
    "        action = action_prime\n",
    "        S = S_prime\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    agent.decay(epsilon_decay_rate=5e-3, lr_decay_rate=5e-4)\n",
    "    \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_frozen_lake():\n",
    "    env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "    es_agent = exp_sarsa_agent(obs_n=env.observation_space.n,  act_n=env.action_space.n, \n",
    "        learning_rate=0.3, gamma = 0.98, e_greed=0.9)\n",
    "\n",
    "    es_reward_list = np.zeros(5000)\n",
    "\n",
    "    for i in range(5000):\n",
    "        es_reward = run_episode_es(env, es_agent)\n",
    "        es_reward_list[i] = es_reward\n",
    "    return es_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_list = run_frozen_lake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, 5000), es_list)\n",
    "avg_list = es_list.reshape(50, 100)\n",
    "avg_list = np.mean(avg_list, axis=1)\n",
    "x_avg = []\n",
    "for i in range (0, 50):\n",
    "    x_avg.append(100 * (i + 1))\n",
    "\n",
    "plt.plot(x_avg, avg_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
