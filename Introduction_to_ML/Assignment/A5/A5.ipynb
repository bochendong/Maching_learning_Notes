{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 5: Decision Trees and Ensemble Methods [ __ / 70  marks]\n",
    "\n",
    "<img src=\"https://datasciencetoday.net/images/2018/11/27/tree.png\">\n",
    "\n",
    "For this assignment we will use standalone and ensembled decision trees (Bagging, AdaBoost) in order to predict whether particular red wines are `high quality` or `low quality` based on some associated input features (e.g., fixed acidity, residual sugar, density, alcohol, etc). \n",
    "\n",
    "We will first import our data. Next, we will apply the pre-processing steps. Finally, we will construct and compare models. There will also be some communication questions along the way. \n",
    "\n",
    "I hope this week's lesson and this assignment will make you more comfortable with using and thinking about decision trees --- they're a very powerful tool."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before you start...\n",
    "* check out the relevant lecture code for reference (`L9_CF.ipynb`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Before you submit...\n",
    "* restart the kernel, then re-run the whole notebook to ensure no errors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1.1 [ _ /3 marks]\n",
    "\n",
    "Read the file `winequality-red.csv` into a pandas DataFrame. Display the first 5 rows of the DataFrame. Make sure to remove the semicolons.\n",
    "\n",
    "`Hint`: Sometimes you will see that dataset entries are separated by `;`,`,`,`&`. You can use the `sep` argument in `read_csv()` to format it properly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "# ****** your code here ******\n",
    "df = pd.read_csv(\"winequality-red.csv\", delimiter=\";\")\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1.2 [ _ /7 marks]\n",
    "\n",
    "Before building our models, we will need to **preprocess** the data. Instead of using the 10-class column ('quality') directly, let's just focus on classifying red wines as `'high quality'` or `'low quality'` by manually assigning a threshold. We will consider wines with 'quality' 7 or higher as **'high quality'** (class label `1`) and those with 'quality' 6 or lower as **'low quality'** (class label `0`). Replace the `quality` column with your new column (`CLASS`). \n",
    "\n",
    "Display the first 5 rows of the new dataframe. How many instances of class `0` and class `1` are there? [ /1 mark] Is the data class-balanced? [ /1 mark] "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# Replace dependent variable 'quality' with `CLASS` (labels 0 and 1) [ /4 marks]\n",
    "# ****** your code here ******\n",
    "\n",
    "label = []\n",
    "Class = df[\"quality\"]\n",
    "\n",
    "num_ones = 0\n",
    "num_zeros = 0\n",
    "for quality in Class:\n",
    "    if (quality >= 7):\n",
    "        label.append(1)\n",
    "        num_ones += 1\n",
    "    else:\n",
    "        label.append(0)\n",
    "        num_zeros += 1\n",
    "\n",
    "df[\"CLASS\"] = label\n",
    "df = df.drop(\"quality\",axis=1)\n",
    "\n",
    "# How many instances of class 0 and class 1 are there in the data? (code) [ /1 mark]\n",
    "# ****** your code here ******\n",
    "\n",
    "print(\"There are %d instances of class `0` and %d class `1` are there\" % (num_zeros, num_ones))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 1382 instances of class `0` and 217 class `1` are there\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "df.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  CLASS  \n",
       "0      9.4      0  \n",
       "1      9.8      0  \n",
       "2      9.8      0  \n",
       "3      9.8      0  \n",
       "4      9.4      0  "
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your Answer**: There are 217 instances of class `1` and 1382 class `0` are there, the class is imbalanced"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1.3 [ _ /3 marks]\n",
    "\n",
    "Let's create our train and test sets. Create an input dataframe X (the input features); next, create an output series y which contains the output class labels (a column of `0`'s and `1`'s). Split the data into train and test sets with `train_test_split`. Use `test_size = 0.3`, `random_state = 0`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# Store the feature data into X; store the class data into y [ /2 marks]\n",
    "# ****** your code here ******\n",
    "X = df.drop(\"CLASS\", axis=1)\n",
    "y = df.CLASS\n",
    "\n",
    "# Do a train-test split. Use 30% of the data for testing. Use random state 0. [ /1 mark]\n",
    "# ****** your code here ******\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = 0.3, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "Xtrain.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.110</td>\n",
       "      <td>19.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.98</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.049</td>\n",
       "      <td>36.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.44</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.080</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.99701</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>10.1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.075</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.99672</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.074</td>\n",
       "      <td>12.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "92              8.6              0.49         0.29             2.0      0.110   \n",
       "1017            8.0              0.18         0.37             0.9      0.049   \n",
       "1447            6.8              0.67         0.00             1.9      0.080   \n",
       "838            10.1              0.31         0.35             1.6      0.075   \n",
       "40              7.3              0.45         0.36             5.9      0.074   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "92                   19.0                 133.0  0.99720  2.93       1.98   \n",
       "1017                 36.0                 109.0  0.99007  2.89       0.44   \n",
       "1447                 22.0                  39.0  0.99701  3.40       0.74   \n",
       "838                   9.0                  28.0  0.99672  3.24       0.83   \n",
       "40                   12.0                  87.0  0.99780  3.33       0.83   \n",
       "\n",
       "      alcohol  \n",
       "92        9.8  \n",
       "1017     12.7  \n",
       "1447      9.7  \n",
       "838      11.2  \n",
       "40       10.5  "
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2.1 [ _ /13 marks]\n",
    "\n",
    "For our first model we will **select a standalone decision tree of optimal maximum depth** (out of possible maximum depths ranging from `2 to 30`). \n",
    "\n",
    "To find the optimal maximum depth, create multiple decision trees with sklearn's `DecisionTreeClassifier` class (you can use a loop), then compute the mean Cross-Validation score for each (use 5-fold CV). You don't need to specify a scorer (Note: for `DecisionTreeClassifier` it's *mean accuracy*).\n",
    "\n",
    "Create a plot which shows the mean CV scores on the y-axis and maximum depths on the x-axis. **Report the optimal maximum depth**. [ /2 marks]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create and fit trees from max_depth 2 to max_depth 30. Use 5-fold CV for each. [ /8 marks]\n",
    "# ****** your code here ******\n",
    "\n",
    "params = {'max_depth': range(2, 30)}\n",
    "\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search_cv =  GridSearchCV(decisiontree, params,verbose = 1, cv=5)\n",
    "grid_search_cv.fit(Xtrain, ytrain)\n",
    "\n",
    "# Plot the mean CV score vs. maximum depth [ /3 marks]\n",
    "# ****** your code here ******\n",
    "plt.plot(range(2, 30), grid_search_cv.cv_results_[\"mean_test_score\"])\n",
    "plt.show()\n",
    "\n",
    "# Report the optimal max_depth either here or in the markdown cell below. [ /2 marks]\n",
    "grid_search_cv.best_params_\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your answer**: the optimal maximum depth is 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2.2 [ _ /6 marks]\n",
    "\n",
    "Consider your optimal max_depth tree (or, you can create a new one with that depth). Fit it to the training set. Report its test accuracy on the test set.\n",
    "\n",
    "Hint: You can use `accuracy_score()` here to report the test accuracy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# Fit your optimal-depth tree, then calculate test accuracy [ /6 marks]\n",
    "# ****** your code here ******\n",
    "decisiontree = DecisionTreeClassifier(max_depth=4)\n",
    "decisiontree.fit(Xtrain, ytrain)\n",
    "\n",
    "y_pred = decisiontree.predict(Xtest)\n",
    "acc_decisiontree = round(accuracy_score(y_pred, ytest) * 100, 2)\n",
    "print(\"The test accuracy on the test set is %.2f.\" % acc_decisiontree)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The test accuracy on the test set is 89.58.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2.3 [ _ /4 marks] \n",
    "\n",
    "What is the **major shortcoming** of standalone decision trees? [ /2 marks] \n",
    "\n",
    "What is the **purpose of creating an ensemble of trees**? [ /2 marks]\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your answer**:\n",
    "\n",
    "What is the **major shortcoming** of standalone decision trees? [ /2 marks] \n",
    "\n",
    "The variance of the standalone decision trees is high.\n",
    "\n",
    "What is the **purpose of creating an ensemble of trees**? [ /2 marks]\n",
    "\n",
    "The purpose of creating an ensemle of trees is to reduce the variance of a decision tree."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3.1 [ _ /24 marks]\n",
    "\n",
    "Let's now focus on creating an **ensemble of 500 trees**. For this question we'll consider Bagging (Bootstrap Aggregation). Follow these steps:\n",
    "* **Step 1**: Create 500 Bootstrap samples (i.e. sample with replacement) from the dataset (specifically, sample from the training data).\n",
    "* **Step 2**: Train a particular tree (`max_depth=4`) on each Bootstrap sample (you'll therefore need 500 trees in total)\n",
    "* **Step 3**: Compute the **overall prediction** of your ensemble on the unseen test set. The overall prediction from each individual test input will come from a vote count from each of the 500 trees. **Report the test accuracy**.\n",
    "\n",
    "To expand on the `voting` point from Step 3: For each test input, each tree will make a certain output prediction. So, for a single test input you'll have 500 votes, and these could be 1 or 0. For the overall prediction for that single test input, you'll count which class (0 or 1) got the most votes.\n",
    "\n",
    "Note: Since this question is meant to be a manually done, you won't get the marks if you use sklearn's `BaggingClassifier` or similar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.ensemble import  BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create 500 Bootstrap samples from the training set. Fit a tree to each [ /12 marks]\n",
    "# ****** your code here ******\n",
    "ntree = 500\n",
    "tree_list = []\n",
    "\n",
    "for i in range(ntree):\n",
    "    newX = Xtrain.sample(Xtrain.shape[0], replace=True)\n",
    "    tree = DecisionTreeClassifier(max_depth=4)\n",
    "    tree.fit(newX, ytrain)\n",
    "\n",
    "    tree_list.append(tree)\n",
    "\n",
    "# Make 500 predictions on the test data (unseen by your trees so far). [ /6 marks] \n",
    "# ****** your code here ******\n",
    "ypred = tree_list[0].predict(Xtest)\n",
    "\n",
    "# Finally, compute the overall vote for each prediction (the most votes for a given class wins) [ /4 marks]\n",
    "# Hint: If there's a tie, the common way is to predict the class with the lowest class label\n",
    "# However, it's also ok to use scipy.stats.mode here (this randomly picks tie winners)\n",
    "# ****** your code here ******\n",
    "y_pred_list = []\n",
    "for i in range(ntree):\n",
    "    y_pred_list.append(ypred)\n",
    "\n",
    "vote_list = []\n",
    "for i in range(480):\n",
    "    num_ones = 0\n",
    "    num_zeros = 0\n",
    "    for j in range (500):\n",
    "        if y_pred_list[j][i] == 0:\n",
    "            num_zeros += 1\n",
    "        else:\n",
    "            num_ones += 1\n",
    "\n",
    "    if (num_ones > num_zeros):\n",
    "        vote_list.append(1)\n",
    "    else:\n",
    "        vote_list.append(0)\n",
    "\n",
    "# Report (print) the accuracy of your ensemble model on the test set. Use accuracy_score() [ /2 marks]\n",
    "# ****** your code here ******\n",
    "acc_decisiontree = round(accuracy_score(vote_list, ytest) * 100, 2)\n",
    "print(acc_decisiontree)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "88.75\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3.2 [ _ /6 marks]\n",
    "\n",
    "Finally, let's consider AdaBoost. Here, each tree (a stump) is trained sequentially and relies on the previous tree for its training data (which was re-sampled, and this was influenced by the sample weight changes as a result of incorrect predictions from the previous tree). \n",
    "\n",
    "Create an `AdaBoostClassifier` object with `base_estimator = DecisionTreeClassifier(max_depth=4)`, `n_estimators=500`, `learning_rate=0.1`. Fit to the training data, and compute (and report) the test accuracy. You can use `accuracy_score()` here.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Create an AdaBoostClassifier object with the specified arguments [ /2 marks]\n",
    "# ****** your code here ******\n",
    "adaboost = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=4), n_estimators=500, learning_rate=0.1)\n",
    "\n",
    "# Fit to the training data and compute the test predictions [ /2 marks]\n",
    "# ****** your code here ******\n",
    "adaboost.fit(Xtrain, ytrain)\n",
    "\n",
    "# Compute and report the test accuracy [ /2 marks]\n",
    "# ****** your code here ******\n",
    "y_pred = adaboost.predict(Xtest)\n",
    "acc_adaboost = round(accuracy_score(y_pred, ytest) * 100, 2)\n",
    "print(\"The test accuracy on the test set is %.2f.\" % acc_adaboost)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The test accuracy on the test set is 91.67.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/dongbochen/Library/Python/3.8/lib/python/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3.3 [ _ /4 marks]\n",
    "\n",
    "Finally, compare the test accuracies of the models considered so far: the optimal max_depth Decision Tree, the bagged ensemble of 500 trees, and the AdaBoost ensemble of 500 trees. Which performed worst? Which performed best? Do the results agree with our intuition from the Lecture?\n",
    "\n",
    "Hint: One intuition you could use from the lecture was that ensemble methods have **lower variance** than a single tree (i.e. less prone to overfitting)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Your answer**:\n",
    "\n",
    "The adaboost performs best, the bagged ensemle of 500 trees perform worst.\n",
    "\n",
    "We can see that the adaboost is better than standalone tree on test set because it reduce the variance than a single tree.\n",
    "\n",
    "Ensemle of 500 trees perform worst is because bagging a poor classifier may make it worse\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}